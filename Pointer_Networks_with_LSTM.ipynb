{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pointer_Networks with LSTM.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/khushbooG9/Pointer-Networks-Using-Fast-Weights/blob/master/Pointer_Networks_with_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "zWFaAnmetOTr",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "tf.enable_eager_execution()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YtdXLAMWr0K1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "tf.random.set_random_seed(42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "wmYMjSIyL2F8"
      },
      "cell_type": "markdown",
      "source": [
        "### Prepare dataset"
      ]
    },
    {
      "metadata": {
        "id": "tbt9vWF3r0K4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "34dc2b65-cfed-4a1c-e4e0-979735f861e2"
      },
      "cell_type": "code",
      "source": [
        "datasize=32*200\n",
        "\n",
        "minSeqSize=3\n",
        "maxSeqSize=3\n",
        "np.random.seed(42)\n",
        "tf.random.set_random_seed(42)\n",
        "\n",
        "dataX=[]\n",
        "\n",
        "for aRec in range(datasize):\n",
        "    seqLen=np.random.randint(minSeqSize,maxSeqSize+1)\n",
        "    aSeq=np.concatenate((np.zeros((1,seqLen),dtype=np.float32),np.random.uniform(size=(1,seqLen)),np.zeros((1,seqLen),dtype=np.float32)),axis=0).T\n",
        "    aSeq1=np.concatenate((np.array([[1,0,0]],dtype=np.float32),aSeq),axis=0)\n",
        "    dataX+=[aSeq1]\n",
        "    \n",
        "dataX=np.array(dataX,dtype=np.float32)\n",
        "encoder_input_data=dataX\n",
        "encoder_input_data.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6400, 4, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "IrswC_jTr0K7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "5e884f71-b5ab-4a02-f665-fcb205d38dd8"
      },
      "cell_type": "code",
      "source": [
        "input_encoder=encoder_input_data[0]\n",
        "input_encoder"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.        , 0.        , 0.        ],\n",
              "       [0.        , 0.37454012, 0.        ],\n",
              "       [0.        , 0.9507143 , 0.        ],\n",
              "       [0.        , 0.7319939 , 0.        ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "9LVsMsRDr0K-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "1447ad94-9826-4116-ebd4-3eb022e1b234"
      },
      "cell_type": "code",
      "source": [
        "encoder_input_data[:5]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[1.        , 0.        , 0.        ],\n",
              "        [0.        , 0.37454012, 0.        ],\n",
              "        [0.        , 0.9507143 , 0.        ],\n",
              "        [0.        , 0.7319939 , 0.        ]],\n",
              "\n",
              "       [[1.        , 0.        , 0.        ],\n",
              "        [0.        , 0.5986585 , 0.        ],\n",
              "        [0.        , 0.15601864, 0.        ],\n",
              "        [0.        , 0.15599452, 0.        ]],\n",
              "\n",
              "       [[1.        , 0.        , 0.        ],\n",
              "        [0.        , 0.05808361, 0.        ],\n",
              "        [0.        , 0.8661761 , 0.        ],\n",
              "        [0.        , 0.601115  , 0.        ]],\n",
              "\n",
              "       [[1.        , 0.        , 0.        ],\n",
              "        [0.        , 0.7080726 , 0.        ],\n",
              "        [0.        , 0.02058449, 0.        ],\n",
              "        [0.        , 0.96990985, 0.        ]],\n",
              "\n",
              "       [[1.        , 0.        , 0.        ],\n",
              "        [0.        , 0.83244264, 0.        ],\n",
              "        [0.        , 0.21233912, 0.        ],\n",
              "        [0.        , 0.18182497, 0.        ]]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "fP-Ji_HMr0LA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "64438dcb-e686-4a02-a0b8-2b1cf12676e2"
      },
      "cell_type": "code",
      "source": [
        "target_data=[]\n",
        "for i in range(dataX.shape[0]):\n",
        "    arr=dataX[i]\n",
        "    x=arr[:,1][1:]\n",
        "    aRec=[([0]*(seqLen+1))+[1]]\n",
        "    aRec=[]\n",
        "    for e in np.sort(x):\n",
        "        idx=list(x).index(e)\n",
        "        aRec+=[np.zeros(seqLen+1,dtype=np.float32)]\n",
        "        aRec[-1][idx+1]=1\n",
        "    aRec+=[np.array([1,0,0,0],dtype=np.float32)]\n",
        "    target_data+=[aRec]\n",
        "target_data=np.array(target_data)\n",
        "print(target_data.shape)\n",
        "target_data[0:2]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(6400, 4, 4)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0., 1., 0., 0.],\n",
              "        [0., 0., 0., 1.],\n",
              "        [0., 0., 1., 0.],\n",
              "        [1., 0., 0., 0.]],\n",
              "\n",
              "       [[0., 0., 0., 1.],\n",
              "        [0., 0., 1., 0.],\n",
              "        [0., 1., 0., 0.],\n",
              "        [1., 0., 0., 0.]]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "niif5bZUr0LD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "247f7e4b-6fe6-41d0-debd-0185fcf81cd1"
      },
      "cell_type": "code",
      "source": [
        "output_pred=target_data[0]\n",
        "output_pred"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1., 0., 0.],\n",
              "       [0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0.],\n",
              "       [1., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "w_jJ77nZr0LG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7eb548e6-5851-48d7-e57d-bc532f85aaf2"
      },
      "cell_type": "code",
      "source": [
        "decoder_dummy_input=np.array([[0,0,1]],dtype=np.float32)\n",
        "decoder_dummy_input=tf.convert_to_tensor(decoder_dummy_input)\n",
        "decoder_dummy_input"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: id=0, shape=(1, 3), dtype=float32, numpy=array([[0., 0., 1.]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "97GlpqgvL8PK"
      },
      "cell_type": "markdown",
      "source": [
        "## Encoder & Decoder Network"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "uqAZrGBMTGDj",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self, hidden_dimensions):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.lstm = layers.LSTM(hidden_dimensions, return_sequences=True, return_state=True)\n",
        "        \n",
        "    def call(self, x):\n",
        "        output, state_h, state_c  = self.lstm(x)        \n",
        "        return output, [state_h, state_c]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "tLNzTuJfWPhk",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "     def __init__(self, hidden_dimensions):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.lstm = layers.LSTM(hidden_dimensions, return_sequences=True, return_state=True)\n",
        "     \n",
        "     def call(self, x, hidden_states):\n",
        "        dec_output, state_h, state_c  = self.lstm(x, initial_state=hidden_states)\n",
        "        # dec_output shape -> (batch_size, 1, hidden_dimension)\n",
        "\n",
        "        return dec_output, [state_h, state_c]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "eTSf9SdkBjcM",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Attention(tf.keras.Model):\n",
        "     def __init__(self, hidden_dimensions):\n",
        "        super(Attention, self).__init__()\n",
        "        # Note: Dense layer -> dot(input, kernel) -> so now Ui = vT . tanh(W1 . e + W2 . di)  becomes Ui = tanh(e . W1 + di . W2) . v\n",
        "        self.W1 = tf.keras.layers.Dense(hidden_dimensions, use_bias=False) # weights -> (256, 256)\n",
        "        self.W2 = tf.keras.layers.Dense(hidden_dimensions, use_bias=False) # weights -> (256, 256)\n",
        "        self.V = tf.keras.layers.Dense(1, use_bias=False) # weights -> (256, 1)\n",
        "        \n",
        "     \n",
        "     def call(self, encoder_outputs, dec_output):\n",
        "        # encoder_outputs shape -> (batch_size, input_sequence_length, hidden_dimension) -> (32, 9, 256)\n",
        "        # dec_output shape -> (batch_size, 1, hidden_dimension) -> (32, 1, 256)\n",
        "\n",
        "        # w1_e -> (*, 9, 256) * (*, 256, 256) -> (*, 9, 256)\n",
        "        w1_e = self.W1(encoder_outputs)\n",
        "        \n",
        "        # w2_e -> (*, 1, 256) * (*, 256, 256) -> (*, 1, 256)\n",
        "        w2_d = self.W2(dec_output)\n",
        "        \n",
        "        # tanh_output -> (*, 9, 256) + (*, 1, 256) -> (*, 9, 256)\n",
        "        tanh_output = tf.nn.tanh(w1_e + w2_d)\n",
        "        \n",
        "        # tanh_output -> (*, 9, 256) + (*, 256, 1) -> (*, 9, 1)\n",
        "        v_dot_tanh = self.V(tanh_output)\n",
        "        \n",
        "        # attention_weights -> (batch_size, input_sequence_length, 1) -> (32, 9, 1)\n",
        "        attention_weights = tf.nn.softmax(v_dot_tanh, axis=1)\n",
        "        \n",
        "        return tf.reshape(attention_weights, (attention_weights.shape[0], attention_weights.shape[1])) # (batch_size, input_sequence_length) -> (32, 9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tB0SDNl5r0LQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "hidden_dimensions=30"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "w_shAefxqfVs"
      },
      "cell_type": "markdown",
      "source": [
        "### Initialize encoder and decoder network"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "xLlEdEXmVFGq",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "encoder = Encoder(hidden_dimensions)\n",
        "decoder = Decoder(hidden_dimensions)\n",
        "attention = Attention(hidden_dimensions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "dUHrlclMqu7L"
      },
      "cell_type": "markdown",
      "source": [
        "### Setup tensorflow dataset for traning "
      ]
    },
    {
      "metadata": {
        "id": "2LPcWsMar0LU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices((encoder_input_data,target_data))\n",
        "batches = 32\n",
        "dataset = dataset.shuffle(100).batch(32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "LkM2Lp_zq3VK"
      },
      "cell_type": "markdown",
      "source": [
        "#### Output of network before training"
      ]
    },
    {
      "metadata": {
        "id": "oZID1ngbr0LY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Initialize values\n",
        "attention_vector_array = []\n",
        "final_output_sequence = []\n",
        "\n",
        "# expand the sequences to be batch size of 1 to be fed as input\n",
        "encoder_input = tf.expand_dims(input_encoder, 0)\n",
        "target_data = tf.expand_dims(output_pred, 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8gSZko9tr0LZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "862105d3-349d-4303-ca65-50253207882b"
      },
      "cell_type": "code",
      "source": [
        "encoder_input"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: id=20, shape=(1, 4, 3), dtype=float32, numpy=\n",
              "array([[[1.        , 0.        , 0.        ],\n",
              "        [0.        , 0.37454012, 0.        ],\n",
              "        [0.        , 0.9507143 , 0.        ],\n",
              "        [0.        , 0.7319939 , 0.        ]]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "Ylamn-bNr0Ld",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "d52777ef-8779-49d9-b57a-186ee8048480"
      },
      "cell_type": "code",
      "source": [
        "target_data"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: id=23, shape=(1, 4, 4), dtype=float32, numpy=\n",
              "array([[[0., 1., 0., 0.],\n",
              "        [0., 0., 0., 1.],\n",
              "        [0., 0., 1., 0.],\n",
              "        [1., 0., 0., 0.]]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "9kGNqxIFr0Lg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "6acf0727-9ff3-4879-de41-a88a65e0dc86"
      },
      "cell_type": "code",
      "source": [
        "# encoder_input shapes -> (batch_size, input_sequence_length, input_dimension)\n",
        "# encoder_outputs shape -> (batch_size, input_sequence_length, hidden_dimension)\n",
        "encoder_outputs, encoder_states = encoder(encoder_input)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:642: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "b7ynWGLgr0Lk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "outputId": "db33350c-2334-4e27-c702-8b022b323496"
      },
      "cell_type": "code",
      "source": [
        "encoder_outputs"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: id=704, shape=(1, 4, 30), dtype=float32, numpy=\n",
              "array([[[-5.01736924e-02,  3.16948779e-02,  4.12515774e-02,\n",
              "         -3.53498310e-02,  4.03320044e-02,  5.54589704e-02,\n",
              "          2.25627013e-02,  7.67772552e-03,  1.25065474e-02,\n",
              "          4.34280075e-02, -3.51917446e-02, -4.26367745e-02,\n",
              "          1.18723800e-02,  1.20848594e-02,  1.52343558e-02,\n",
              "          2.52943626e-03,  3.65303047e-02, -2.87996512e-02,\n",
              "         -3.56858447e-02, -3.98900062e-02, -3.35637480e-02,\n",
              "          3.72589752e-02,  4.25086394e-02,  5.63450158e-04,\n",
              "          4.19360884e-02,  2.39714514e-02,  3.57869896e-03,\n",
              "         -1.72660686e-02,  1.52625805e-02,  3.94967645e-02],\n",
              "        [-2.22421326e-02,  2.47765277e-02,  3.65987234e-02,\n",
              "         -4.23405543e-02,  1.13524478e-02,  3.23084295e-02,\n",
              "          1.95754655e-02, -9.81311128e-03, -7.96766859e-03,\n",
              "          3.69066931e-02, -4.04213220e-02, -3.13852206e-02,\n",
              "          2.37852950e-02,  3.13127926e-03, -5.76501770e-05,\n",
              "          9.14086215e-03,  4.37631737e-03, -2.99506970e-02,\n",
              "         -3.45080420e-02, -4.46596146e-02, -1.02595314e-02,\n",
              "          4.62127067e-02,  4.93345298e-02,  7.97919463e-03,\n",
              "          2.17703842e-02,  2.76661627e-02,  1.46138901e-02,\n",
              "         -2.45807022e-02,  1.55701367e-02,  4.59963679e-02],\n",
              "        [ 8.66505317e-03,  2.86554862e-02,  3.18578631e-02,\n",
              "         -7.33130276e-02, -4.35565412e-02,  1.94004998e-02,\n",
              "          1.60721354e-02, -4.54331934e-02, -3.86707820e-02,\n",
              "          4.41719554e-02, -6.83179200e-02, -2.92353090e-02,\n",
              "          5.09941764e-02, -6.88682962e-03, -1.39657762e-02,\n",
              "          2.46766843e-02, -4.06503417e-02, -4.75885384e-02,\n",
              "         -5.39057106e-02, -7.68605992e-02,  2.67241821e-02,\n",
              "          8.01792219e-02,  6.70465752e-02,  1.65961497e-02,\n",
              "         -6.33274950e-03,  3.19205895e-02,  3.69472168e-02,\n",
              "         -4.57401611e-02,  1.08126206e-02,  7.60974139e-02],\n",
              "        [ 2.44398303e-02,  3.20355855e-02,  2.15802602e-02,\n",
              "         -9.16588530e-02, -7.11324364e-02,  9.00421944e-03,\n",
              "          1.56689771e-02, -5.97160198e-02, -4.91048656e-02,\n",
              "          4.00895737e-02, -7.52905011e-02, -1.76418740e-02,\n",
              "          6.61576614e-02, -1.01019060e-02, -1.68897379e-02,\n",
              "          3.57778445e-02, -5.76706156e-02, -4.83256727e-02,\n",
              "         -7.00005069e-02, -9.08174068e-02,  4.36393470e-02,\n",
              "          9.21928734e-02,  7.15480670e-02,  2.03076061e-02,\n",
              "         -1.58893298e-02,  2.62703821e-02,  4.58792970e-02,\n",
              "         -5.89044616e-02,  7.21261650e-03,  8.86569768e-02]]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "mOizExHir0Lm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "45c98402-0d19-4f0d-f003-9ece1fe5ac3d"
      },
      "cell_type": "code",
      "source": [
        "encoder_states"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor: id=690, shape=(1, 30), dtype=float32, numpy=\n",
              " array([[ 0.02443983,  0.03203559,  0.02158026, -0.09165885, -0.07113244,\n",
              "          0.00900422,  0.01566898, -0.05971602, -0.04910487,  0.04008957,\n",
              "         -0.0752905 , -0.01764187,  0.06615766, -0.01010191, -0.01688974,\n",
              "          0.03577784, -0.05767062, -0.04832567, -0.07000051, -0.09081741,\n",
              "          0.04363935,  0.09219287,  0.07154807,  0.02030761, -0.01588933,\n",
              "          0.02627038,  0.0458793 , -0.05890446,  0.00721262,  0.08865698]],\n",
              "       dtype=float32)>,\n",
              " <tf.Tensor: id=673, shape=(1, 30), dtype=float32, numpy=\n",
              " array([[ 0.05119281,  0.06086827,  0.04373739, -0.19406971, -0.14232066,\n",
              "          0.01806413,  0.03184876, -0.12546046, -0.09462173,  0.07565732,\n",
              "         -0.15041617, -0.03344038,  0.12792736, -0.01976309, -0.03190866,\n",
              "          0.06723674, -0.1205032 , -0.09313053, -0.13895768, -0.18442363,\n",
              "          0.08514079,  0.18679911,  0.14010568,  0.04275992, -0.03289884,\n",
              "          0.05114478,  0.09684512, -0.12279087,  0.01411788,  0.18446338]],\n",
              "       dtype=float32)>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "MGUBBYqyr0Lr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "25c04235-ec41-4bf8-f814-5be09e3e182e"
      },
      "cell_type": "code",
      "source": [
        "# first decoder input '=>'\n",
        "dec_input = tf.expand_dims(decoder_dummy_input, 1)\n",
        "dec_input"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: id=709, shape=(1, 1, 3), dtype=float32, numpy=array([[[0., 0., 1.]]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "metadata": {
        "id": "sLHK34ror0Lu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# loading the final encoder states to decoder network as initial hidden states\n",
        "decoder_states = encoder_states"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": false,
        "id": "2-EnOrVFr0Lw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "a0c139bb-2adb-4cf7-96c0-219f6e75f8b4"
      },
      "cell_type": "code",
      "source": [
        "print(\"\\nPrediction for \")\n",
        "for i in range(0, encoder_input.shape[1]):\n",
        "    decoder_output, decoder_states = decoder(dec_input, decoder_states)\n",
        "    target_prediction = attention(encoder_outputs, decoder_output)\n",
        "    \n",
        "    # Save the attention vector\n",
        "    attention_vector_array.append(target_prediction.numpy()[0])\n",
        "    final_output_sequence.append(np.round(target_prediction.numpy()[0])) # why use np.round here ?? why not np.argmax ??\n",
        "    print(\"%dth position -> %d -> %s\"%(i, np.argmax(target_prediction), str(encoder_input[:,np.argmax(target_prediction)])))\n",
        "    \n",
        "    # pass the predicted value as next input state to decoder network\n",
        "    dec_input = tf.expand_dims(encoder_input[:, np.argmax(target_prediction)], 1) # works only for one input combination\n",
        "\n",
        "print(\"\\nTarget output values (softmax values over the input sequence size)\")\n",
        "print(target_data.numpy()[0])\n",
        "print(\"\\nPredicted output values\")\n",
        "print(np.array(final_output_sequence))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Prediction for \n",
            "0th position -> 0 -> tf.Tensor([[1. 0. 0.]], shape=(1, 3), dtype=float32)\n",
            "1th position -> 0 -> tf.Tensor([[1. 0. 0.]], shape=(1, 3), dtype=float32)\n",
            "2th position -> 0 -> tf.Tensor([[1. 0. 0.]], shape=(1, 3), dtype=float32)\n",
            "3th position -> 0 -> tf.Tensor([[1. 0. 0.]], shape=(1, 3), dtype=float32)\n",
            "\n",
            "Target output values (softmax values over the input sequence size)\n",
            "[[0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]\n",
            " [1. 0. 0. 0.]]\n",
            "\n",
            "Predicted output values\n",
            "[[0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "01MfSZZoMNwM"
      },
      "cell_type": "markdown",
      "source": [
        "### Train Model"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "WGwifkQinyC4",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "optimizer = tf.train.AdamOptimizer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "9uolR2wiKDUQ",
        "outputId": "d54ffec0-0765-4bda-faf6-a2884abdbba1",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1530
        }
      },
      "cell_type": "code",
      "source": [
        "epochs = 4 # was over fitting beyond this\n",
        "loss_history = []\n",
        "total_attention = []\n",
        "for epoch in range(epochs):\n",
        "    # encoder_input shapes -> (batch_size, input_sequence_length, input_dimension)\n",
        "    print(\"NEW EPOCH:\",epoch)\n",
        "    for (batch, (encoder_input, target_data)) in enumerate(dataset):\n",
        "        loss = 0\n",
        "        with tf.GradientTape() as tape:\n",
        "            encoder_outputs, encoder_states = encoder(encoder_input)\n",
        "            # encoder_outputs shape -> (batch_size, input_sequence_length, hidden_state_dimension) -> (32, 9, 256)\n",
        "            # encoder states shape -> (batch_size, hidden_state_dimension) -> (32, 256)\n",
        "    \n",
        "            # first decoder input '=>'\n",
        "            # dec_input shape -> (batch_size, input_lenght=1, input_dimension) -> (32, 1, 64)\n",
        "            # dec_input = tf.expand_dims(encoder_input[:, 0], 1) # The '=>' symbol loaded as input\n",
        "            dec_input = tf.tile(tf.expand_dims(decoder_dummy_input, 1),tf.convert_to_tensor(np.array([batches,1,1])))\n",
        "            \n",
        "            # loading the final encoder states to decoder network as initial hidden states\n",
        "            # decoder states shape -> (batch_size, hidden_state_dimension) -> (32, 256)\n",
        "            decoder_states = encoder_states\n",
        "\n",
        "            # track attention over each output sequence\n",
        "            attention_vector_array = []\n",
        "            \n",
        "            # iterrate over the times of input sequence size or till the output points to '=>' symbol\n",
        "            for i in range(0, encoder_input.shape[1]):\n",
        "                # decoder outputs shape -> (batch_size, input_lenght=1, hidden_state_dimension) -> (32, 1, 256)\n",
        "                # decoder states shape -> (batch_size, hidden_state_dimension) -> (32, 256)\n",
        "                decoder_output, decoder_states = decoder(dec_input, decoder_states)\n",
        "\n",
        "                # target prediction -> (batch_size, input_sequence_length) -> (32, 9)\n",
        "                # target prediction points to one of the input sequence element -> element with highest value\n",
        "                target_prediction = attention(encoder_outputs, decoder_output)\n",
        "\n",
        "                if batch % 10 == 0:\n",
        "                    attention_vector_array.append(target_prediction.numpy()[0])\n",
        "\n",
        "                # used for training the network by using the target data\n",
        "                tar_data = target_data[:, i]\n",
        "                \n",
        "                tarCounter=0\n",
        "                ei_slice_stack=[]\n",
        "                for tar_data_slice in tar_data:\n",
        "                    ei_slice_stack+=[encoder_input[tarCounter,np.argmax(tar_data_slice)]]\n",
        "                ei_slice_stack=tf.convert_to_tensor(np.array(ei_slice_stack,dtype=np.float32))\n",
        "                    \n",
        "                    \n",
        "                \n",
        "                # load the input state to decoder network for next prediction\n",
        "                dec_input = tf.expand_dims(ei_slice_stack, 1) # Works only for one input combination\n",
        "\n",
        "                # loss value calculated as categorical crossentropy\n",
        "                loss += tf.reduce_mean(tf.keras.backend.categorical_crossentropy(tar_data, target_prediction))\n",
        "        batch_loss = (loss / batches)\n",
        "        if batch % 10 == 0:\n",
        "            total_attention.append(attention_vector_array)\n",
        "            print(\"\\tEpoch {:03d}/{:03d}: Loss at step {:02d}: {:.9f}\".format((epoch+1), epochs, batch, tf.reduce_mean(tf.keras.backend.categorical_crossentropy(tar_data, target_prediction))))\n",
        "        # store the loss history \n",
        "        loss_history.append(batch_loss.numpy())\n",
        "        # fetch the trainable variables\n",
        "        variables = encoder.variables + decoder.variables\n",
        "        # calculate the gradient\n",
        "        grads = tape.gradient(loss, variables)\n",
        "        # update the weights of the network\n",
        "        optimizer.apply_gradients(zip(grads, variables), global_step=tf.train.get_or_create_global_step())\n",
        "    print(\"Epoch {:03d}/{:03d} completed \\t - \\tBatch loss: {:.9f}\".format((epoch+1), epochs, tf.reduce_mean(tf.keras.backend.categorical_crossentropy(tar_data, target_prediction))))\n",
        "print(\"Final loss: {:.9f}\".format(tf.reduce_mean(tf.keras.backend.categorical_crossentropy(tar_data, target_prediction))))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NEW EPOCH: 0\n",
            "\tEpoch 001/004: Loss at step 00: 1.365067959\n",
            "\tEpoch 001/004: Loss at step 10: 1.394328713\n",
            "\tEpoch 001/004: Loss at step 20: 1.381916761\n",
            "\tEpoch 001/004: Loss at step 30: 1.390063286\n",
            "\tEpoch 001/004: Loss at step 40: 1.389225364\n",
            "\tEpoch 001/004: Loss at step 50: 1.374649882\n",
            "\tEpoch 001/004: Loss at step 60: 1.364059448\n",
            "\tEpoch 001/004: Loss at step 70: 1.316788793\n",
            "\tEpoch 001/004: Loss at step 80: 1.266419768\n",
            "\tEpoch 001/004: Loss at step 90: 1.196208954\n",
            "\tEpoch 001/004: Loss at step 100: 1.060602069\n",
            "\tEpoch 001/004: Loss at step 110: 0.957106352\n",
            "\tEpoch 001/004: Loss at step 120: 0.847798467\n",
            "\tEpoch 001/004: Loss at step 130: 0.774947643\n",
            "\tEpoch 001/004: Loss at step 140: 0.697331131\n",
            "\tEpoch 001/004: Loss at step 150: 0.653275430\n",
            "\tEpoch 001/004: Loss at step 160: 0.617102385\n",
            "\tEpoch 001/004: Loss at step 170: 0.551599145\n",
            "\tEpoch 001/004: Loss at step 180: 0.507576168\n",
            "\tEpoch 001/004: Loss at step 190: 0.494732380\n",
            "Epoch 001/004 completed \t - \tBatch loss: 0.490682870\n",
            "NEW EPOCH: 1\n",
            "\tEpoch 002/004: Loss at step 00: 0.473555803\n",
            "\tEpoch 002/004: Loss at step 10: 0.445723176\n",
            "\tEpoch 002/004: Loss at step 20: 0.421553433\n",
            "\tEpoch 002/004: Loss at step 30: 0.406043023\n",
            "\tEpoch 002/004: Loss at step 40: 0.398641169\n",
            "\tEpoch 002/004: Loss at step 50: 0.377864122\n",
            "\tEpoch 002/004: Loss at step 60: 0.370969534\n",
            "\tEpoch 002/004: Loss at step 70: 0.361075640\n",
            "\tEpoch 002/004: Loss at step 80: 0.347664058\n",
            "\tEpoch 002/004: Loss at step 90: 0.340813279\n",
            "\tEpoch 002/004: Loss at step 100: 0.336871564\n",
            "\tEpoch 002/004: Loss at step 110: 0.327919841\n",
            "\tEpoch 002/004: Loss at step 120: 0.317969918\n",
            "\tEpoch 002/004: Loss at step 130: 0.311302364\n",
            "\tEpoch 002/004: Loss at step 140: 0.306342304\n",
            "\tEpoch 002/004: Loss at step 150: 0.304475427\n",
            "\tEpoch 002/004: Loss at step 160: 0.298557937\n",
            "\tEpoch 002/004: Loss at step 170: 0.289060175\n",
            "\tEpoch 002/004: Loss at step 180: 0.284180582\n",
            "\tEpoch 002/004: Loss at step 190: 0.285765588\n",
            "Epoch 002/004 completed \t - \tBatch loss: 0.282110959\n",
            "NEW EPOCH: 2\n",
            "\tEpoch 003/004: Loss at step 00: 0.280491471\n",
            "\tEpoch 003/004: Loss at step 10: 0.272629291\n",
            "\tEpoch 003/004: Loss at step 20: 0.269142509\n",
            "\tEpoch 003/004: Loss at step 30: 0.265915900\n",
            "\tEpoch 003/004: Loss at step 40: 0.265653193\n",
            "\tEpoch 003/004: Loss at step 50: 0.259718895\n",
            "\tEpoch 003/004: Loss at step 60: 0.255950868\n",
            "\tEpoch 003/004: Loss at step 70: 0.253684580\n",
            "\tEpoch 003/004: Loss at step 80: 0.249209389\n",
            "\tEpoch 003/004: Loss at step 90: 0.246559888\n",
            "\tEpoch 003/004: Loss at step 100: 0.244865239\n",
            "\tEpoch 003/004: Loss at step 110: 0.239471778\n",
            "\tEpoch 003/004: Loss at step 120: 0.235421807\n",
            "\tEpoch 003/004: Loss at step 130: 0.232099071\n",
            "\tEpoch 003/004: Loss at step 140: 0.229982942\n",
            "\tEpoch 003/004: Loss at step 150: 0.229302257\n",
            "\tEpoch 003/004: Loss at step 160: 0.226304948\n",
            "\tEpoch 003/004: Loss at step 170: 0.221062303\n",
            "\tEpoch 003/004: Loss at step 180: 0.219312578\n",
            "\tEpoch 003/004: Loss at step 190: 0.221714929\n",
            "Epoch 003/004 completed \t - \tBatch loss: 0.216655612\n",
            "NEW EPOCH: 3\n",
            "\tEpoch 004/004: Loss at step 00: 0.214997053\n",
            "\tEpoch 004/004: Loss at step 10: 0.211093485\n",
            "\tEpoch 004/004: Loss at step 20: 0.211657986\n",
            "\tEpoch 004/004: Loss at step 30: 0.208169907\n",
            "\tEpoch 004/004: Loss at step 40: 0.209536165\n",
            "\tEpoch 004/004: Loss at step 50: 0.206441298\n",
            "\tEpoch 004/004: Loss at step 60: 0.204628557\n",
            "\tEpoch 004/004: Loss at step 70: 0.206839293\n",
            "\tEpoch 004/004: Loss at step 80: 0.202694893\n",
            "\tEpoch 004/004: Loss at step 90: 0.201791212\n",
            "\tEpoch 004/004: Loss at step 100: 0.201673493\n",
            "\tEpoch 004/004: Loss at step 110: 0.199090123\n",
            "\tEpoch 004/004: Loss at step 120: 0.198236346\n",
            "\tEpoch 004/004: Loss at step 130: 0.196457922\n",
            "\tEpoch 004/004: Loss at step 140: 0.196844041\n",
            "\tEpoch 004/004: Loss at step 150: 0.197719544\n",
            "\tEpoch 004/004: Loss at step 160: 0.196451813\n",
            "\tEpoch 004/004: Loss at step 170: 0.191676795\n",
            "\tEpoch 004/004: Loss at step 180: 0.191306412\n",
            "\tEpoch 004/004: Loss at step 190: 0.196683064\n",
            "Epoch 004/004 completed \t - \tBatch loss: 0.192374036\n",
            "Final loss: 0.192374036\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "0fcEN_jWXrbk"
      },
      "cell_type": "markdown",
      "source": [
        "#### Attention plot over the input sequence"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "4vJ1vMKzSevq",
        "outputId": "571d063e-1e1e-49da-f955-a2881c80c9bd",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 642
        }
      },
      "cell_type": "code",
      "source": [
        "figstep=20\n",
        "fig = plt.figure(figsize=(250,250))\n",
        "for i in range(1, len(total_attention),figstep):\n",
        "    fig.add_subplot(len(total_attention)/4, len(total_attention)/4, int(i/figstep)+1).matshow(np.array(total_attention[i-1]), cmap='YlGn')\n",
        "plt.show()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAACpgAAAJdCAYAAAAs1+aLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 18000x18000 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "0GCUvlzuXxya"
      },
      "cell_type": "markdown",
      "source": [
        "### Loss plot over the entire training sequence"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "miigFwpMW_lO",
        "outputId": "5b7d55a8-781a-47f3-8cd1-e6a0fbc2a29f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "cell_type": "code",
      "source": [
        "plt.plot(loss_history)\n",
        "\n",
        "plt.ylabel('loss value')\n",
        "plt.xlabel('batches')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFiIiEtP/B10UklhASL2+AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "dWkPK4bKxwuN"
      },
      "cell_type": "markdown",
      "source": [
        "### Inference Model"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "7wrftwSNLy-4"
      },
      "cell_type": "markdown",
      "source": [
        "#### Output of network before training"
      ]
    },
    {
      "metadata": {
        "id": "BiuMMbnrr0L_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "59bf6dd0-cb2a-454b-fb54-6d9f09850c2e"
      },
      "cell_type": "code",
      "source": [
        "input_encoder[1,1]=0.1\n",
        "input_encoder[2,1]=0.9\n",
        "input_encoder[3,1]=0.5\n",
        "print(input_encoder)\n",
        "target_data1=[]\n",
        "arr=input_encoder\n",
        "x=arr[:,1][1:]\n",
        "aRec=[([0]*(seqLen+1))+[1]]\n",
        "aRec=[]\n",
        "for e in np.sort(x):\n",
        "    idx=list(x).index(e)\n",
        "    aRec+=[np.zeros(seqLen+1,dtype=np.float32)]\n",
        "    aRec[-1][idx+1]=1\n",
        "aRec+=[np.array([1,0,0,0],dtype=np.float32)]\n",
        "target_data1+=[aRec]\n",
        "target_data1=np.array(target_data1)\n",
        "print(target_data1.shape)\n",
        "output_pred=target_data1\n",
        "output_pred"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.  0.  0. ]\n",
            " [0.  0.1 0. ]\n",
            " [0.  0.9 0. ]\n",
            " [0.  0.5 0. ]]\n",
            "(1, 4, 4)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0., 1., 0., 0.],\n",
              "        [0., 0., 0., 1.],\n",
              "        [0., 0., 1., 0.],\n",
              "        [1., 0., 0., 0.]]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "uTnwRFAFJuN5",
        "outputId": "fe093dde-f5db-492f-d4f9-b2bebe4075ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "cell_type": "code",
      "source": [
        "#Initialize values\n",
        "attention_vector_array = []\n",
        "final_output_sequence = []\n",
        "\n",
        "# expand the sequences to be batch size of 1 to be fed as input\n",
        "encoder_input = tf.expand_dims(input_encoder, 0)\n",
        "target_data = tf.expand_dims(output_pred, 0)\n",
        "\n",
        "# encoder_input shapes -> (number_of_inputs, input_sequence_length, input_dimension)\n",
        "# encoder_outputs shape -> (number_of_inputs, input_sequence_length, hidden_dimension)\n",
        "encoder_outputs, encoder_states = encoder(encoder_input)\n",
        "\n",
        "# first decoder input '=>'\n",
        "dec_input = tf.expand_dims(encoder_input[:, 0], 1)\n",
        "\n",
        "# loading the final encoder states to decoder network as initial hidden states\n",
        "decoder_states = encoder_states\n",
        "\n",
        "print(\"\\nPrediction for \")\n",
        "for i in range(0, encoder_input.shape[1]):\n",
        "#     print()\n",
        "    decoder_output, decoder_states = decoder(dec_input, decoder_states)\n",
        "    target_prediction = attention(encoder_outputs, decoder_output)\n",
        "#     print(target_prediction)\n",
        "    # Save the attention vector\n",
        "    attention_vector_array.append(target_prediction.numpy()[0])\n",
        "    o=np.argmax(target_prediction.numpy()[0])\n",
        "    x=np.zeros((4))\n",
        "    x[o]=1\n",
        "    final_output_sequence.append(x)\n",
        "    print(\"%dth position -> %d -> %s\"%(i, np.argmax(target_prediction), str(encoder_input[:,np.argmax(target_prediction)])))\n",
        "\n",
        "    # pass the predicted value as next input state to decoder network\n",
        "    dec_input = tf.expand_dims(encoder_input[:, np.argmax(target_prediction)], 1) # works only for one input combination\n",
        "\n",
        "print(\"\\nTarget output values (softmax values over the input sequence size)\")\n",
        "print(target_data.numpy()[0])\n",
        "print(\"\\nPredicted output values\")\n",
        "print(np.array(final_output_sequence))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Prediction for \n",
            "0th position -> 1 -> tf.Tensor([[0.  0.1 0. ]], shape=(1, 3), dtype=float32)\n",
            "1th position -> 2 -> tf.Tensor([[0.  0.9 0. ]], shape=(1, 3), dtype=float32)\n",
            "2th position -> 2 -> tf.Tensor([[0.  0.9 0. ]], shape=(1, 3), dtype=float32)\n",
            "3th position -> 0 -> tf.Tensor([[1. 0. 0.]], shape=(1, 3), dtype=float32)\n",
            "\n",
            "Target output values (softmax values over the input sequence size)\n",
            "[[[0. 1. 0. 0.]\n",
            "  [0. 0. 0. 1.]\n",
            "  [0. 0. 1. 0.]\n",
            "  [1. 0. 0. 0.]]]\n",
            "\n",
            "Predicted output values\n",
            "[[0. 1. 0. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [1. 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Llvy5120OSGX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "98e935df-ce7a-44fb-b70a-dee18330802a"
      },
      "cell_type": "code",
      "source": [
        "target_prediction.numpy().T"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.81595695],\n",
              "       [0.07664619],\n",
              "       [0.05912579],\n",
              "       [0.04827117]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Szl9S7PwjGVn",
        "outputId": "04468302-e1a5-4da1-bda5-00d5badb223d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "np.array(attention_vector_array)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.05136254, 0.33156893, 0.3013986 , 0.31566995],\n",
              "       [0.03330924, 0.31449947, 0.33630517, 0.31588605],\n",
              "       [0.04223281, 0.28690168, 0.37474245, 0.29612306],\n",
              "       [0.81595695, 0.07664619, 0.05912579, 0.04827117]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "5EkUHT0HHAhV"
      },
      "cell_type": "markdown",
      "source": [
        "References:\n",
        "\n",
        "* https://arxiv.org/pdf/1506.03134.pdf\n",
        "* https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense"
      ]
    }
  ]
}