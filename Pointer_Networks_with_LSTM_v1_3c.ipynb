{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pointer_Networks_with_LSTM_v1-3c.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/khushbooG9/Pointer-Networks-Using-Fast-Weights/blob/master/Pointer_Networks_with_LSTM_v1_3c.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "y9rWiYuRrp0f",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "- Dev incorporation in training\n",
        "- Inference print layout difference\n",
        "- Better multi epoch training code\n",
        "- Updated loss to per output\n",
        "- Function for data prep"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "zWFaAnmetOTr",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime as dt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-zyK1oRMrp0l",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tf.enable_eager_execution()\n",
        "np.random.seed(42)\n",
        "tf.random.set_random_seed(42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KH5gPEjcrp0n",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Experiment Configuration"
      ]
    },
    {
      "metadata": {
        "id": "sWdDXmrXrp0n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b4aad9f5-d602-4d8b-a558-bb3ab4d92df2"
      },
      "cell_type": "code",
      "source": [
        "hidden_dimensions=100\n",
        "\n",
        "minSeqSize=3\n",
        "maxSeqSize=6\n",
        "\n",
        "batchSize=16\n",
        "numOfBatches=100\n",
        "datasize=batchSize*numOfBatches*(maxSeqSize-minSeqSize+1)\n",
        "datasize"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6400"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "wmYMjSIyL2F8"
      },
      "cell_type": "markdown",
      "source": [
        "### Prepare dataset"
      ]
    },
    {
      "metadata": {
        "id": "CS-oQ9TQrp0q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def makeData(minSeqSize,maxSeqSize,batchSize,numOfBatches):\n",
        "    X={}\n",
        "    Y={}\n",
        "    datasize=batchSize*numOfBatches*(maxSeqSize-minSeqSize+1)\n",
        "    \n",
        "    for seqLen in range(minSeqSize,maxSeqSize+1):\n",
        "        X[seqLen]=[]\n",
        "        X[seqLen]=[]\n",
        "        Y[seqLen]=[]\n",
        "        Y[seqLen]=[]\n",
        "\n",
        "\n",
        "        for dataidx in range(int(datasize/(maxSeqSize-minSeqSize+1))):\n",
        "\n",
        "            # aSeq:\n",
        "            #       - seqLen x 2\n",
        "            #       - col 1: zero and col 2: numbers\n",
        "\n",
        "            # X\n",
        "            seqBase=np.random.uniform(size=(1,seqLen-1))\n",
        "            aSeq=np.concatenate((np.zeros((1,seqLen-1),dtype=np.float32),seqBase),axis=0)\n",
        "            aSeq=aSeq.T\n",
        "            aSeq=np.concatenate((np.array([[1,0]],dtype=np.float32),aSeq),axis=0)\n",
        "            X[seqLen]+=[aSeq]\n",
        "\n",
        "            # Y\n",
        "            aRec=[]\n",
        "            for e in np.sort(seqBase[0]):\n",
        "                idx=list(seqBase[0]).index(e)\n",
        "                aRec+=[np.zeros(seqLen,dtype=np.float32)]\n",
        "                aRec[-1][idx+1]=1\n",
        "            aRec+=[np.zeros(seqLen,dtype=np.float32)]\n",
        "            aRec[-1][0]=1\n",
        "            Y[seqLen]+=[aRec]\n",
        "\n",
        "\n",
        "        X[seqLen]=np.array(X[seqLen],dtype=np.float32)\n",
        "        Y[seqLen]=np.array(Y[seqLen],dtype=np.float32)\n",
        "    return X,Y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NuO8Af9grp0s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "trainX,trainY=makeData(minSeqSize,maxSeqSize,batchSize,numOfBatches)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dsYIS0Terp0t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f84fff34-d68b-4ada-c04c-f671aa2ba242"
      },
      "cell_type": "code",
      "source": [
        "print('Train X for',minSeqSize,':',trainX[minSeqSize].shape)\n",
        "print('Train Y for',minSeqSize,':',trainY[minSeqSize].shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train X for 3 : (1600, 3, 2)\n",
            "Train Y for 3 : (1600, 3, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "97GlpqgvL8PK"
      },
      "cell_type": "markdown",
      "source": [
        "## Encoder & Decoder Network"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "uqAZrGBMTGDj",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self, hidden_dimensions):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.lstm = layers.CuDNNLSTM(hidden_dimensions, return_sequences=True, return_state=True)\n",
        "        \n",
        "    def call(self, x):\n",
        "        output, state_h, state_c  = self.lstm(x)        \n",
        "        return output, [state_h, state_c]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "tLNzTuJfWPhk",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "     def __init__(self, hidden_dimensions):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.lstm = layers.CuDNNLSTM(hidden_dimensions, return_sequences=True, return_state=True)\n",
        "     \n",
        "     def call(self, x, hidden_states):\n",
        "        dec_output, state_h, state_c  = self.lstm(x, initial_state=hidden_states)\n",
        "        # dec_output shape -> (batch_size, 1, hidden_dimension)\n",
        "\n",
        "        return dec_output, [state_h, state_c]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "eTSf9SdkBjcM",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Attention(tf.keras.Model):\n",
        "     def __init__(self, hidden_dimensions):\n",
        "        super(Attention, self).__init__()\n",
        "        # Note: Dense layer -> dot(input, kernel) -> so now Ui = vT . tanh(W1 . e + W2 . di)  becomes Ui = tanh(e . W1 + di . W2) . v\n",
        "        self.W1 = tf.keras.layers.Dense(hidden_dimensions, use_bias=False) # weights -> (256, 256)\n",
        "        self.W2 = tf.keras.layers.Dense(hidden_dimensions, use_bias=False) # weights -> (256, 256)\n",
        "        self.V = tf.keras.layers.Dense(1, use_bias=False) # weights -> (256, 1)\n",
        "        \n",
        "     \n",
        "     def call(self, encoder_outputs, dec_output):\n",
        "        # encoder_outputs shape -> (batch_size, input_sequence_length, hidden_dimension) -> (32, 9, 256)\n",
        "        # dec_output shape -> (batch_size, 1, hidden_dimension) -> (32, 1, 256)\n",
        "\n",
        "        # w1_e -> (*, 9, 256) * (*, 256, 256) -> (*, 9, 256)\n",
        "        w1_e = self.W1(encoder_outputs)\n",
        "        \n",
        "        # w2_e -> (*, 1, 256) * (*, 256, 256) -> (*, 1, 256)\n",
        "        w2_d = self.W2(dec_output)\n",
        "        \n",
        "        # tanh_output -> (*, 9, 256) + (*, 1, 256) -> (*, 9, 256)\n",
        "        tanh_output = tf.nn.tanh(w1_e + w2_d)\n",
        "        \n",
        "        # tanh_output -> (*, 9, 256) + (*, 256, 1) -> (*, 9, 1)\n",
        "        v_dot_tanh = self.V(tanh_output)\n",
        "        \n",
        "        # attention_weights -> (batch_size, input_sequence_length, 1) -> (32, 9, 1)\n",
        "        attention_weights = tf.nn.softmax(v_dot_tanh, axis=1)\n",
        "        \n",
        "        return tf.reshape(attention_weights, (attention_weights.shape[0], attention_weights.shape[1])) # (batch_size, input_sequence_length) -> (32, 9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "w_shAefxqfVs"
      },
      "cell_type": "markdown",
      "source": [
        "### Initialize encoder and decoder network"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "xLlEdEXmVFGq",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "encoder = Encoder(hidden_dimensions)\n",
        "decoder = Decoder(hidden_dimensions)\n",
        "attention = Attention(hidden_dimensions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZiwTmjWWrp02",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Batch Infer Function"
      ]
    },
    {
      "metadata": {
        "id": "N0C6_Sz_rp03",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def infer(encoder,decoder,attention,X,Y,verbose=0):\n",
        "    loss=0\n",
        "    \n",
        "    if verbose==2:\n",
        "        print('X:')\n",
        "        print(X)\n",
        "        print('Y:')\n",
        "        print(Y)\n",
        "\n",
        "    #Initialize values\n",
        "    attention_vector_array = []\n",
        "    final_output_sequence = []\n",
        "\n",
        "    encoder_input, target_data=X,Y\n",
        "    # encoder_input -> (batch_size, input_sequence_length, input_dimension)\n",
        "    # target_data -> (batch_size, input_sequence_length, input_sequence_length)\n",
        "\n",
        "    # run the decoder\n",
        "    encoder_outputs, encoder_states = encoder(encoder_input)\n",
        "\n",
        "    # prepare initial decoder input\n",
        "    dec_input = tf.convert_to_tensor(np.array([[[0,0]]]*X.shape[0],dtype=np.float32))\n",
        "    # dec_input -> (batch_size, 1, input_dimension)\n",
        "\n",
        "    # loading the final encoder states to decoder network as initial hidden states\n",
        "    decoder_states = encoder_states\n",
        "    # decoder states -> (batch_size, hidden_state_dimension)\n",
        "\n",
        "    # iterrate over the times of input sequence size\n",
        "    if verbose==2:\n",
        "        print('\\n\\nPREDICTIONS')\n",
        "        print('-----------')\n",
        "    \n",
        "    result=[]\n",
        "    for i in range(0, encoder_input.shape[1]):\n",
        "        result+=[[0]*encoder_input.shape[0]]\n",
        "        # run decoder's single step for one input\n",
        "        decoder_output, decoder_states = decoder(dec_input, decoder_states)\n",
        "        # decoder outputs -> (batch_size, input_lenght=1, hidden_state_dimension)\n",
        "        # decoder states -> (batch_size, hidden_state_dimension)\n",
        "\n",
        "        # target prediction -> (batch_size, input_sequence_length)\n",
        "        # target prediction points to one of the input sequence element -> element with highest value\n",
        "        target_prediction = attention(encoder_outputs, decoder_output)\n",
        "\n",
        "        # used for training the network by using the target data\n",
        "        ei_slice_stack=[]\n",
        "        tarCounter=0\n",
        "        for tar_data_slice in target_prediction:\n",
        "            ei_slice_stack+=[encoder_input[tarCounter,np.argmax(tar_data_slice)]]\n",
        "            tarCounter+=1\n",
        "        ei_slice_stack=tf.convert_to_tensor(np.array(ei_slice_stack,dtype=np.float32))\n",
        "\n",
        "        if verbose==2:\n",
        "            outputCounter=0\n",
        "            print('\\nFor position:',i)\n",
        "            for x in X:\n",
        "                print(\"\\tInput %d, Predicted:%d->%s\"%(outputCounter,np.argmax(target_prediction[outputCounter]), str(x[np.argmax(target_prediction[outputCounter])])),\n",
        "                     '\\tExpected:%d->%s:'%(np.argmax(target_data[outputCounter,i]),encoder_input[outputCounter,np.argmax(target_data[outputCounter,i])]))\n",
        "                outputCounter+=1\n",
        "        if verbose==1:\n",
        "            outputCounter=0\n",
        "            for x in X:\n",
        "                result[-1][outputCounter]=encoder_input[outputCounter,np.argmax(target_prediction[outputCounter])]\n",
        "                outputCounter+=1\n",
        "\n",
        "\n",
        "        loss += tf.reduce_mean(tf.keras.backend.categorical_crossentropy(target_data[:,i], target_prediction))\n",
        "        \n",
        "        # load the input state to decoder network for next prediction\n",
        "        dec_input = tf.expand_dims(ei_slice_stack, 1)\n",
        "\n",
        "    if verbose==1:\n",
        "        outputCounter=-1\n",
        "        for x in X:\n",
        "            outputCounter+=1\n",
        "            print('\\n===== PREDICTED:',outputCounter,'=====\\n')\n",
        "            for i in range(0, encoder_input.shape[1]):\n",
        "                print('\\t-',result[i][outputCounter])\n",
        "            print('\\n--- ACTUAL:',outputCounter,'---\\n')\n",
        "            for i in range(0, encoder_input.shape[1]):\n",
        "                print('\\t-',encoder_input[outputCounter][np.argmax(target_data[outputCounter][i])])\n",
        "\n",
        "            \n",
        "    return loss.numpy()/(X.shape[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "LkM2Lp_zq3VK"
      },
      "cell_type": "markdown",
      "source": [
        "#### Output of network before training"
      ]
    },
    {
      "metadata": {
        "scrolled": false,
        "id": "TRc1TdSrrp05",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        },
        "outputId": "ad70bb25-93fa-4be0-bbea-05b8a20eb89d"
      },
      "cell_type": "code",
      "source": [
        "# Use data point\n",
        "seqLen=minSeqSize\n",
        "infer(encoder,decoder,attention,trainX[seqLen][0:2],trainY[seqLen][0:2],1)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:642: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "InternalError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-31c108c7ddf1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mseqLen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mminSeqSize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mseqLen\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mseqLen\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-11-de057b761e22>\u001b[0m in \u001b[0;36minfer\u001b[0;34m(encoder, decoder, attention, X, Y, verbose)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# run the decoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# prepare initial decoder input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    590\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;31m# Eager execution on data tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 592\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    593\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-b49375c6ab99>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_c\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstate_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_c\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m     \u001b[0;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    590\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;31m# Eager execution on data tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 592\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    593\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/cudnn_recurrent.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask, training, initial_state)\u001b[0m\n\u001b[1;32m    109\u001b[0m       \u001b[0;31m# Reverse time axis.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m       \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m     \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/cudnn_recurrent.py\u001b[0m in \u001b[0;36m_process_batch\u001b[0;34m(self, inputs, initial_state)\u001b[0m\n\u001b[1;32m    499\u001b[0m         \u001b[0minput_c\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_c\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 501\u001b[0;31m         is_training=True)\n\u001b[0m\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_state\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_cudnn_rnn_ops.py\u001b[0m in \u001b[0;36mcudnn_rnn\u001b[0;34m(input, input_h, input_c, params, rnn_mode, input_mode, direction, dropout, seed, seed2, is_training, name)\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0minput_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_training\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m             ctx=_ctx)\n\u001b[0m\u001b[1;32m    108\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SymbolicException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_cudnn_rnn_ops.py\u001b[0m in \u001b[0;36mcudnn_rnn_eager_fallback\u001b[0;34m(input, input_h, input_c, params, rnn_mode, input_mode, direction, dropout, seed, seed2, is_training, name, ctx)\u001b[0m\n\u001b[1;32m    188\u001b[0m   \"is_training\", is_training)\n\u001b[1;32m    189\u001b[0m   _result = _execute.execute(b\"CudnnRNN\", 4, inputs=_inputs_flat,\n\u001b[0;32m--> 190\u001b[0;31m                              attrs=_attrs, ctx=_ctx, name=name)\n\u001b[0m\u001b[1;32m    191\u001b[0m   _execute.record_gradient(\n\u001b[1;32m    192\u001b[0m       \"CudnnRNN\", _inputs_flat, _attrs, _result, name)\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_keras_symbolic_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
            "\u001b[0;31mInternalError\u001b[0m: Could not find valid device for node.\nNode: {{node CudnnRNN}}\nAll kernels registered for op CudnnRNN :\n  <no registered kernels>\n [Op:CudnnRNN]"
          ]
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "01MfSZZoMNwM"
      },
      "cell_type": "markdown",
      "source": [
        "### Train Model"
      ]
    },
    {
      "metadata": {
        "id": "dER3y_P7rp07",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Prep training data"
      ]
    },
    {
      "metadata": {
        "id": "hZegfAE5rp08",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batchedDataset={}\n",
        "for seqLen in range(minSeqSize,maxSeqSize+1):\n",
        "    batchedDataset[seqLen]=[]\n",
        "    for aBatch in tf.data.Dataset.from_tensor_slices((trainX[seqLen],trainY[seqLen])).batch(batchSize):\n",
        "        batchedDataset[seqLen]+=[aBatch]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v5EutlgJrp0-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Config and run training"
      ]
    },
    {
      "metadata": {
        "id": "sA7UgeVErp0-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lastepoch=0\n",
        "optimizer = tf.train.AdamOptimizer()\n",
        "\n",
        "loss_history = []\n",
        "wholeLoss_history=[]\n",
        "devLoss_history=[]\n",
        "total_attention = []\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GYNF6TS2rp1B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "devBatchSize=64\n",
        "overfitFlag=False\n",
        "tolWindow=5\n",
        "tol=0.5\n",
        "simtolWindow=10\n",
        "simtolFraction=0.01"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DT5Eb-mbrp1D",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "overfitFlag=False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": false,
        "id": "HrfsigX4rp1F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for epoch in range(lastepoch,epochs+lastepoch):\n",
        "    if overfitFlag:\n",
        "        break\n",
        "    print(\"NEW EPOCH:\",epoch+1)\n",
        "    lastepoch=epoch\n",
        "    for batch in range(numOfBatches):\n",
        "        wholeLoss=0\n",
        "        for seqLen in range(minSeqSize,maxSeqSize+1):\n",
        "            # init batch specific parameters\n",
        "            loss=0\n",
        "            with tf.GradientTape() as tape:            \n",
        "                # get data for this batch\n",
        "                encoder_input, target_data=batchedDataset[seqLen][batch]\n",
        "                # encoder_input -> (batch_size, input_sequence_length, input_dimension)\n",
        "                # target_data -> (batch_size, input_sequence_length, input_sequence_length)\n",
        "\n",
        "                # run the decoder\n",
        "                encoder_outputs, encoder_states = encoder(encoder_input)\n",
        "\n",
        "                # prepare initial decoder input\n",
        "                dec_input = tf.convert_to_tensor(np.array([[[0,0]]]*batchSize,dtype=np.float32))\n",
        "                # dec_input -> (batch_size, 1, input_dimension)\n",
        "\n",
        "                # loading the final encoder states to decoder network as initial hidden states\n",
        "                decoder_states = encoder_states\n",
        "                # decoder states -> (batch_size, hidden_state_dimension)\n",
        "\n",
        "                # iterrate over the times of input sequence size\n",
        "                for i in range(encoder_input.shape[1]):\n",
        "                    # run decoder's single step for one input\n",
        "                    decoder_output, decoder_states = decoder(dec_input, decoder_states)\n",
        "                    # decoder outputs -> (batch_size, input_lenght=1, hidden_state_dimension)\n",
        "                    # decoder states -> (batch_size, hidden_state_dimension)\n",
        "\n",
        "                    # target prediction -> (batch_size, input_sequence_length)\n",
        "                    # target prediction points to one of the input sequence element -> element with highest value\n",
        "                    target_prediction = attention(encoder_outputs, decoder_output)\n",
        "\n",
        "                    # used for training the network by using the target data\n",
        "                    tar_data = target_data[:, i]                \n",
        "                    tarCounter=0\n",
        "                    ei_slice_stack=[]\n",
        "                    for tar_data_slice in tar_data:\n",
        "                        ei_slice_stack+=[encoder_input[tarCounter,np.argmax(tar_data_slice)]]\n",
        "                        tarCounter+=1\n",
        "                    ei_slice_stack=tf.convert_to_tensor(np.array(ei_slice_stack,dtype=np.float32))\n",
        "\n",
        "                    # load the input state to decoder network for next prediction\n",
        "                    dec_input = tf.expand_dims(ei_slice_stack, 1)\n",
        "\n",
        "                    # loss value calculated as categorical crossentropy for output i averaged across the batch\n",
        "                    loss += tf.reduce_mean(tf.keras.backend.categorical_crossentropy(tar_data, target_prediction))\n",
        "\n",
        "            # loss per output for a batch of same sized seq\n",
        "            batch_loss = (loss / (encoder_input.shape[1].value))\n",
        "\n",
        "            # combined loss per output across batches of ALL seq sizes\n",
        "            wholeLoss+=batch_loss\n",
        "\n",
        "            # fetch the trainable variables\n",
        "            variables = encoder.variables + decoder.variables\n",
        "            \n",
        "            # calculate the gradient\n",
        "            grads = tape.gradient(loss, variables)\n",
        "            \n",
        "            # update the weights of the network\n",
        "            optimizer.apply_gradients(zip(grads, variables), global_step=tf.train.get_or_create_global_step())\n",
        "            \n",
        "            # store the loss history \n",
        "            loss_history.append(batch_loss.numpy())\n",
        "\n",
        "        # normalize wholeLoss\n",
        "        wholeLoss=(wholeLoss/(maxSeqSize-minSeqSize+1))\n",
        "        \n",
        "        # store the loss history \n",
        "        wholeLoss_history.append(wholeLoss.numpy())\n",
        "        \n",
        "\n",
        "            \n",
        "        if batch % 10 == 0:\n",
        "            print(\"\\tEpoch {:03d}/{:03d}: Loss at step {:02d}: {:.9f}\".format((epoch+1), epochs, batch, tf.reduce_mean(tf.keras.backend.categorical_crossentropy(tar_data, target_prediction))),dt.now())\n",
        "            # check if we need to stop for over-fitting or training stablizing\n",
        "            devLoss=0\n",
        "            for seqLen in range(minSeqSize,maxSeqSize+1):\n",
        "                devX,devY=makeData(seqLen,seqLen,devBatchSize,1)\n",
        "                devLoss+=infer(encoder,decoder,attention,devX[seqLen],devY[seqLen])\n",
        "            devLoss=(devLoss/(maxSeqSize-minSeqSize+1))\n",
        "            devLoss_history.append(devLoss)\n",
        "\n",
        "            if abs(wholeLoss-devLoss)/wholeLoss>tol and devLoss>wholeLoss:\n",
        "                print('Dev loss too different than Train loss. Stopping Training')\n",
        "                overfitFlag=True\n",
        "                break\n",
        "\n",
        "#             if np.argmin(np.array(wholeLoss_history))<len(wholeLoss_history)-tolWindow:\n",
        "#                 print('Train loss seems to be going up. Stopping Training')\n",
        "#                 overfitFlag=True\n",
        "#                 break            \n",
        "\n",
        "            print('\\t               WholeLoss:',np.round(wholeLoss.numpy(),5),'DevLoss:',np.round(devLoss,5))\n",
        "\n",
        "\n",
        "\n",
        "    print(\"Epoch {:03d}/{:03d} completed \\t - \\tBatch loss: {:.9f}\".format((epoch+1), epochs, tf.reduce_mean(tf.keras.backend.categorical_crossentropy(tar_data, target_prediction))),dt.now())\n",
        "print(\"Final loss: {:.9f}\".format(tf.reduce_mean(tf.keras.backend.categorical_crossentropy(tar_data, target_prediction))),dt.now())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "0GCUvlzuXxya"
      },
      "cell_type": "markdown",
      "source": [
        "#### Loss plot over the entire training sequence"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "miigFwpMW_lO",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.plot(loss_history)\n",
        "plt.ylabel('loss value')\n",
        "plt.xlabel('batches')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ySe7cdhArp1K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.plot(wholeLoss_history)\n",
        "plt.ylabel('wholeLoss value')\n",
        "plt.xlabel('batches')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nR8v-8CYrp1M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.plot(devLoss_history)\n",
        "plt.ylabel('devLoss value')\n",
        "plt.xlabel('batches')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3D8wqL9Rrp1O",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Inference"
      ]
    },
    {
      "metadata": {
        "id": "gj8KZRWIrp1O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Use data point\n",
        "for seqLen in [minSeqSize,int((minSeqSize+maxSeqSize)/2)]+list(range(maxSeqSize,maxSeqSize+5)):\n",
        "    X,Y=makeData(seqLen,seqLen,5,1)\n",
        "    print('Seq:',seqLen)\n",
        "    print('\\tloss:',infer(encoder,decoder,attention,X[seqLen],Y[seqLen],1))\n",
        "    print('\\n\\n==============\\n\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jr47onx3rp1Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# AFTER 15 EPOCHS\n",
        "# # Use data point\n",
        "# for seqLen in [minSeqSize,int((minSeqSize+maxSeqSize)/2)]+list(range(maxSeqSize,maxSeqSize+5)):\n",
        "#     X,Y=makeData(seqLen,seqLen,5,1)\n",
        "#     print('Seq:',seqLen)\n",
        "#     print('\\tloss:',infer(encoder,decoder,attention,X[seqLen],Y[seqLen],1))\n",
        "#     print('\\n\\n==============\\n\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TGScfolJrp10",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nK1yoiwmrp12",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}